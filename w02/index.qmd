---
title: "Week 2: {{< var w02.title >}}"
subtitle: "*DSAN 5500: Data Structures, Objects, and Algorithms in Python*"
date: 2026-01-15
date-format: full
lecnum: 2
categories:
  - "Class Sessions"
author: "Jeff Jacobs"
institute: "<a href='mailto:jj1088@georgetown.edu' target='_blank'>`jj1088@georgetown.edu`</a>"
bibliography: "../_DSAN5500.bib"
jupyter: python3
format:
  revealjs:
    df-print: kable
    output-file: "slides.html"
    footer: "DSAN 5500 Week 2: {{< var w02.footer >}}"
    echo: true
    code-fold: show
    scrollable: true
    slide-number: true
    html-math-method: mathjax
    link-external-icon: true
    link-external-newwindow: true
    theme: [default, "../dsan-globals/jjquarto.scss"]
    include-in-header:
      text: "<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css'><link rel='preconnect' href='https://fonts.googleapis.com'><link rel='preconnect' href='https://fonts.gstatic.com' crossorigin><link href='https://fonts.googleapis.com/css2?family=Honk&display=swap' rel='stylesheet'><link rel='stylesheet' type='text/css' href='https://cdn.jsdelivr.net/gh/dreampulse/computer-modern-web-font@master/fonts.css'>"
    simplemenu:
      flat: true
      barhtml:
        header: "<div class='menubar'><span style='position: absolute; left: 8; padding-left: 8px;'><a href='./index.html'>&larr; Return to Notes</a></span><ul class='menu'></ul></div>"
      scale: 0.5
    revealjs-plugins:
      - simplemenu
  html:
    df-print: kable
    output-file: "index.html"
    echo: true
    code-fold: show
    html-math-method: mathjax
---

::: {.content-visible unless-format="revealjs"}

<center>
<a class="h2" href="./slides.html" target="_blank">Open slides in new window &rarr;</a>
</center>

:::

# Where We Left Off: Primitive Types {.smaller .title-12 .math-80 data-stack-name="Stack-Heap"}

:::: {.columns}
::: {.column width="33%"}

<center>

<i class='bi bi-1-circle'></i> `None`

$$
\underset{\text{\small{Always 0}}}{\underline{\hspace{16mm}}}
$$

</center>

```{python}
#| label: prim-none
x = None
type(x)
```

:::
::: {.column width="33%"}

<center>

<i class='bi bi-2-circle'></i> Boolean (`True` or `False`)

$$
\underset{\{0,1\}}{\underline{\hspace{12mm}}}
$$

</center>

```{python}
#| label: prim-boolean
x = True
type(x)
```

:::
::: {.column width="34%"}

<center>

<i class='bi bi-3-circle'></i> Numbers (`int`, `float`)<br>

$$
\small{\underset{\small{\{0,1\}}}{\underline{\hspace{8mm}}}~
\underset{\small{\{0,1\}}}{\underline{\hspace{8mm}}}~
\underset{\small{\{0,1\}}}{\underline{\hspace{8mm}}}~
\underset{\small{\{0,1\}}}{\underline{\hspace{8mm}}}~
\underset{\small{\{0,1\}}}{\underline{\hspace{8mm}}}~
\underset{\small{\{0,1\}}}{\underline{\hspace{8mm}}}~
\underset{\small{\{0,1\}}}{\underline{\hspace{8mm}}}~
\underset{\small{\{0,1\}}}{\underline{\hspace{8mm}}}}
$$

</center>

```{python}
#| label: prim-numeric
x = 3
print(type(x))
y = 3.14
type(y)
```

:::
::::

* Why do we distinguish these from all other types? Computer **knows in advance how much space they'll take up!** (`None`: 1 bit, `bool`: 1 bit, `int`: 32/64 bits)

## Primitive Types: Python Weirdness Edition {.title-08 .crunch-title .crunch-ul .crunch-quarto-figure}

:::: {.columns}
::: {.column width="50%"}

`None`: **1** bit (Always `0`)

```{python}
#| label: none-size
#| echo: true
#| code-fold: false
import sys
sys.getsizeof(None)
```

Boolean (`True` or `False`): Exactly **1** bit (`0` or `1`)

```{python}
#| label: bool-size
#| echo: true
#| code-fold: false
sys.getsizeof(True)
```

`int`: [32 or 64 bits](https://docs.python.org/3/library/sys.html#sys.maxsize) (depending on OS)

```{python}
#| label: int-size
#| echo: true
#| code-fold: false
sys.maxsize
```

:::
::: {.column width="50%"}

![](images/atrick_nocap.jpg){fig-align="center"}

<center>

Why is this happening?

</center>

:::
::::

## Stack and Heap *in C / Java* {.smaller}

::: columns
::: {.column width="40%"}

``` {.c filename="my_beautiful_app.c"}
time_t current_time = time(NULL);
int num_rows = 13;
bool filled = true;
bool empty = false;
int num_cols = 2;
char username[] = "Jeff";
int i = 0;
int j = None;
void z = NULL;
```

:::
::: {.column width="60%"}



<!-- https://kroki.io/graphviz/svg/eNqVkl1v2jAUhq_hV1hmF60EWj6AUkQsTeyjqrZetNVuKKpMfEy8BjuynQIj-e-zQwudVmntuXB07LyPz3t8mFhqWmRoiXZt5EJT-cCETr5fN2mqZArSamohudUltFumXOwVaV4aC_pb4JStVk4XkCf4B6yU3qKTT9wdoaligL5sIC2tUPJ0jKboI7qkjxQ7xT-gsAEdUDeWpg-4qeJlGPtItZk1P6EE4d1uIukKQpKW-p65OitZru61WpuKizwHVsGqsNtmN1W5qUoD2isqUf2qftfVbkIZ0yEJNqPRYgjx8Lya8JCEsftExJtGJ-GpS_rkK82NywKfDUjk1qGT8TOe9mMIXDoifj0nV0qCpwQkDvt1jbsmowX4cjWkSjPc5UpaX0WCp6rUAjSeO_P1a32J_u7LBdDiZVuyEM2ejj47-7MoiOJecNaLovlr13QLkGvBbJYE84bSaiDxAXKHL4HzO_wm8T46KBsc9N77f7Xe6rMa758Uj5t3QD2CcBbi8XIwM3abO4JRuXAtc7No3CQKaZtRnKNOd_N0508Ba3ysqPPhCOX9IzF6JjJqMngX8sgbel4Wt52D-g9b6P_t -->

![](images/stack-heap-c.svg){fig-align="center"}

:::
:::

## Stack and Heap *in Python* {.smaller}

:::: {.columns}
::: {.column width="45%"}

``` {.python filename="my_beautiful_app.py"}
import datetime
cur_date = datetime.datetime.now()
num_rows = 13
filled = True
empty = False
num_cols = 2
username = "Jeff"
i = 0
j = None
z = 314
```

:::
::: {.column width="55%"}

<!-- https://kroki.io/graphviz/svg/eNqVk0uP0zAUhdftr7A8LEBqRd59KImEhscIAUKA2HSqkZPcNGZSO7Id2tLkv-O47bSILKZeOLo-vp-PTuyMrgSpCrRC-yHSQxD2mFERffpmypSzFJgSREH0Q9QwHMg6OXSkZS0ViA-W7hwMSpJAGeHPsOZih16-ybWEbnkG6N0W0lpRzl7N0dedKjjDev9_GNtgnkDfFUkfsfFwOaT6TYRcmE0oQni_DxlZgx2ntXjItMuG1esHwTeyyWlZQtbAulI7s5ryUja1BNF1NLT51fxpm31IskzYsbWdTpMA3GDWhLkd267-OHo1cV0_nXiBLj1dBnbgkRw61Y8dPQd6MZ_kqeeCpctp3M2zAy6xrFm307Zi1_baFo9kQSrofAtIucjwKOdMdXYifMtrQUHgpU6h7QvI-TegOyDVZT6FjRZH6a3OYeFYjju2JmPHWfYdM6qAbWimishaGsrAQNwnyD3-CHl-j5_VfLTgnbrDMIm76xK-TuL4CoB_CXhPSnk1IbgkfOHseYAu8hMCH-4YnpuLgcYxwoWN5yt_IdWu1ATJS6p_nX4aUj8MypR5GUt0M9oes_tJYYPPtm5enKG5dyY6J2JGZAFXIc88p-MVXo8SGMXtUYyHwu9RZkYJhjqP9i_dCD4S -->

![](images/stack-heap-singleton.svg){fig-align="center"}

:::
::::

## Side-by-Side

:::: {.columns}
::: {.column width="50%"}

![](images/stack-heap-c.svg){fig-align="center"}

:::
::: {.column width="50%"}

<!-- https://kroki.io/graphviz/svg/eNqVk0uP0zAUhdftr7A8LEBqRd59KImEhscIAUKA2HSqkZPcNGZSO7Id2tLkv-O47bSILKZeOLo-vp-PTuyMrgSpCrRC-yHSQxD2mFERffpmypSzFJgSREH0Q9QwHMg6OXSkZS0ViA-W7hwMSpJAGeHPsOZih16-ybWEbnkG6N0W0lpRzl7N0dedKjjDev9_GNtgnkDfFUkfsfFwOaT6TYRcmE0oQni_DxlZgx2ntXjItMuG1esHwTeyyWlZQtbAulI7s5ryUja1BNF1NLT51fxpm31IskzYsbWdTpMA3GDWhLkd267-OHo1cV0_nXiBLj1dBnbgkRw61Y8dPQd6MZ_kqeeCpctp3M2zAy6xrFm307Zi1_baFo9kQSrofAtIucjwKOdMdXYifMtrQUHgpU6h7QvI-TegOyDVZT6FjRZH6a3OYeFYjju2JmPHWfYdM6qAbWimishaGsrAQNwnyD3-CHl-j5_VfLTgnbrDMIm76xK-TuL4CoB_CXhPSnk1IbgkfOHseYAu8hMCH-4YnpuLgcYxwoWN5yt_IdWu1ATJS6p_nX4aUj8MypR5GUt0M9oes_tJYYPPtm5enKG5dyY6J2JGZAFXIc88p-MVXo8SGMXtUYyHwu9RZkYJhjqP9i_dCD4S -->

![](images/stack-heap-singleton.svg){fig-align="center"}

:::
::::

# Algorithmic Thinking {data-stack-name="Algorithms"}

* What are the **inputs**?
* What are the **outputs**?
* **Standard** cases vs. **corner cases**
* **Adversarial** development: brainstorm all of the ways an evil hacker might break your code!

## Example: Finding An Item Within A List {.title-08}

* Seems straightforward, right? Given a list `l`, and a value `v`, return the index of `l` which contains `v`
* **Corner cases** galore...
* What if `l` contains `v` more than once? What if it doesn't contain `v` at all? What if `l` is `None`? What if `v` is `None`? What if `l` isn't a list at all? What if `v` is itself a list?

## Corner Cases {.crunch-title .crunch-ul}

* Most people stand in the center of a room...
* Eccentric weirdos stand in the corner
* Your algorithm needs to handle **all people**

![](images/guy-in-corner-of-party.jpg){fig-align="center"}

## Demo

[Streamlit Dictionary Lookup Demo](https://dict-lookup.streamlit.app/)

# Data Structures: Motivation {data-stack-name="Data Structures"}

## Why Does NYC Subway Have Express Lines? {.smaller .title-10}

![From <a href='https://www.centralpark.com/visitor-info/get-directions/' target='_blank'>NYC Central Park website</a>](images/subway_map_nyc.jpg){fig-align="center"}

## Why Stop At Two Levels? {.smaller}

![From <a href='https://blog.reachsumit.com/posts/2020/07/skip-list/' target='_blank'>Skip List Data Structure Explained</a>, Sumit's Diary blog](images/nyc-7.png){fig-align="center"}

## How TF Does Google Maps Work? {.smaller .crunch-iframe .crunch-title .crunch-ul}

* A (mostly) full-on answer: soon to come! Data structures for spatial data
* A step in that direction: **Quadtrees**! (**Fractal DC**)

```{=html}
<iframe src="https://jimkang.com/quadtreevis/" width="100%" height="450"></iframe>
```
<a href='https://jimkang.com/quadtreevis/' target='_blank'>Jim Kang's Quadtree Visualizations</a>

# Algorithmic Complexity: Motivation {data-stack-name="Complexity"}

## The Secretly Exciting World of Matrix Multiplication

* Fun Fact 1: Most of modern Machine Learning is, at the processor level, just a bunch of matrix operations
* Fun Fact 2: The way we've all learned how to multiply matrices requires $O(N^3)$ operations, for two $N \times N$ matrices $A$ and $B$
* Fun Fact 3: $\underbrace{x^2 - y^2}_{\mathclap{\times\text{ twice, }\pm\text{ once}}} = \underbrace{(x+y)(x-y)}_{\times\text{once, }\pm\text{ twice}}$
* Fun Fact 4: These are not very fun facts at all

## Why Is Jeff Rambling About Matrix Math From 300 Years Ago? {.smaller}

* The way we all learned it in school (for $N = 2$):

$$
AB = \begin{bmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{bmatrix}
\begin{bmatrix}
b_{11} & b_{12} \\
b_{21} & b_{22}
\end{bmatrix} =
\begin{bmatrix}
a_{11}b_{11} + a_{12}b_{21} & a_{11}b_{12} + a_{12}b_{22} \\
a_{21}b_{11} + a_{22}b_{21} & a_{21}b_{12} + a_{22}b_{22}
\end{bmatrix}
$$

* 12 operations: 8 multiplications, 4 additions $\implies O(N^3) = O(2^3) = O(8)$
* Are we trapped? Like... what is there to do besides performing these $N^3$ operations, if we want to multiply two $N \times N$ matrices? Why are we about to move onto yet another slide about this?

## Block-Partitioning Matrices {.smaller}

* Now let's consider **big** matrices, whose dimensions are a power of 2 (for ease of illustration): $A$ and $B$ are now $N \times N = 2^n \times 2^n$ matrices
* We can "decompose" the matrix product $AB$ as:

$$
AB = \begin{bmatrix}
A_{11} & A_{12} \\
A_{21} & A_{22}
\end{bmatrix}
\begin{bmatrix}
B_{11} & B_{12} \\
B_{21} & B_{22}
\end{bmatrix} =
\begin{bmatrix}
A_{11}B_{11} + A_{12}B_{21} & A_{11}B_{12} + A_{12}B_{22} \\
A_{21}B_{11} + A_{22}B_{21} & A_{21}B_{12} + A_{22}B_{22}
\end{bmatrix}
$$

* Which gives us a **recurrence relation** representing the total number of computations required for this big-matrix multiplication: $T(N) = \underbrace{8T(N/2)}_{\text{Multiplications}} + \underbrace{\Theta(1)}_{\text{Additions}}$
* It turns out that (using a method we'll learn in Week 3), given this recurrence relation and our **base case** from the previous slide, this divide-and-conquer approach via block-partitioning doesn't help us: we still get $T(n) = O(n^3)$...
* So why is Jeff still torturing us with this example?

## Time For Some ðŸª„MATRIX MAGIC!ðŸª„ {.smaller .crunch-title .crunch-ul .crunch-math .crunch-li .title-12}

::: {#matrix-magic-defn}

* If we define

$$
\begin{align*}
m_1 &= (a_{11}+a_{22})(b_{11}+b_{22}) \\
m_2 &= (a_{21}+a_{22})b_{11} \\
m_3 &= a_{11}(b_{12}-b_{22}) \\
m_4 &= a_{22}(b_{21}-b_{11}) \\
m_5 &= (a_{11}+a_{12})b_{22} \\
m_6 &= (a_{21}-a_{11})(b_{11}+b_{12}) \\
m_7 &= (a_{12}-a_{22})(b_{21}+b_{22})
\end{align*}
$$

:::
::: {#matrix-magic-result}

* Then we can combine these **seven** scalar products to obtain our matrix product:

$$
AB = \begin{bmatrix}
m_1 + m_4 - m_5 + m_7 & m_3 + m_5 \\
m_2 + m_4 & m_1 - m_2 + m_3 + m_6
\end{bmatrix}
$$

:::

* Total operations: 7 multiplications, 18 additions

## Block-Partitioned Matrix Magic {.smaller}

* Using the previous slide as our **base case** and applying this same method to the block-paritioned big matrices, we get the same result, but where the four entries in $AB$ here are now **matrices** rather than scalars:

$$
AB = \begin{bmatrix}
M_1 + M_4 - M_5 + M_7 & M_3 + M_5 \\
M_2 + M_4 & M_1 - M_2 + M_3 + M_6
\end{bmatrix}
$$

* We now have a **different recurrence relation**: $T(N) = \underbrace{7T(N/2)}_{\text{Multiplications}} + \underbrace{\Theta(N^2)}_{\text{Additions}}$
* And it turns out, somewhat miraculously, that the additional time required for the **increased number of additions** is **significantly less** than the **time savings** we obtain by doing 7 instead of 8 multiplications, since this method now runs in $T(N) = O(N^{\log_2(7)}) \approx O(N^{2.807}) < O(N^3)$ ðŸ¤¯
