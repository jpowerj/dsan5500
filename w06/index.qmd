---
title: "Week 6: Hash Tables and BST Iteration"
subtitle: "*DSAN 5500: Data Structures, Objects, and Algorithms in Python*"
date: 2026-02-12
date-format: full
author: "Jeff Jacobs"
institute: "[`jj1088@georgetown.edu`](mailto:jj1088@georgetown.edu)"
lecnum: 6
categories:
  - "Class Sessions"
format:
  revealjs:
    df-print: kable
    output-file: "slides.html"
    footer: "DSAN 5500 Week 6: {{< var w06.footer >}}"
    echo: true
    code-fold: show
    scrollable: true
    slide-number: true
    html-math-method: mathjax
    include-in-header:
      text: "<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css'><link rel='preconnect' href='https://fonts.googleapis.com'><link rel='preconnect' href='https://fonts.gstatic.com' crossorigin><link href='https://fonts.googleapis.com/css2?family=Honk&display=swap' rel='stylesheet'><link rel='stylesheet' type='text/css' href='https://cdn.jsdelivr.net/gh/dreampulse/computer-modern-web-font@master/fonts.css'>"
    theme: [default, "../dsan-globals/jjquarto.scss"]
    simplemenu:
      flat: true
      barhtml:
        header: "<div class='menubar'><span style='position: absolute; left: 8; padding-left: 8px;'><a href='./index.html'>&larr; Return to Notes</a></span><ul class='menu'></ul></div>"
      scale: 0.5
    revealjs-plugins:
      - simplemenu
  html:
    df-print: kable
    output-file: "index.html"
    echo: true
    code-fold: show
    html-math-method: mathjax
---

::: {.content-visible unless-format="revealjs"}

<center>
<a class="h2" href="./slides.html" target="_blank">Open slides in new window &rarr;</a>
</center>

:::

# Schedule {.smaller .small-title .crunch-title .crunch-callout .code-90 data-name="Schedule"}

Today's Planned Schedule:

| | Start | End | Topic |
|:- |:- |:- |:- |
| **Lecture** | 6:30pm | 6:40pm | [HW2 Intro &rarr;](#hash-tables) |
| | 6:40pm | 7:30pm | 
| | 7:30pm | 8:00pm | [(Those Who Know...) It's the Same Algorithm ü§Ø &rarr;](#onwards-and-upwards-fancier-algorithms) |
| **Break!** | 8:00pm | 8:10pm | |
| | 8:10pm | 9:00pm | [BST Iteration: BFS and DFS &rarr;](#onwards-and-upwards-fancier-algorithms) |

: {tbl-colwidths="[12,12,12,64]"}

{{< include ../dsan-globals/_graphviz-setup.qmd >}}

# Hash Tables {data-stack-name="HashTable"}

* *(Spoiler alert, so you know I'm not lying to you: this is a **LinkedList** with some **additional structure!**)*
* You just got hired as a **cashier** (Safeway cashiering alum myself ü´°)
* The scanner is broken (spoiler #2: the scanner uses a hash table), so you start writing down **items** along with their **prices**, one-by-one, as items come in...

## Our List of (Item, Price) Pairs {.crunch-title .crunch-details .crunch-ul .small-summary .text-90}

```{python}
price_list = []
price_list.append(('Banana', 10))
price_list.append(('Apple', 2))
price_list.append(('Four Loko', 5))
price_list
```

* As the list gets longer, it gets harder and harder to **find where you wrote down a specific item and its price**
* As you now know, you could use **linear search**, $\overline{O}(n)$, or if you ensure alphabetical order (an **invariant!**), you could use **binary, divide-and-conquer search**, $\overline{O}(\log_2(n))$
* We can do **even better**: $\overline{O}(1)$. First w/magic, but then math

## Strange-At-First Technique for Algorithm Analysis: Oracles

* What if we had a magical wizard who could just **tell us** where to find an item we were looking for?
* Sounds like I'm joking/saying *"what if we had a billion $ and infinite charisma and could fly and walk through walls"*
* Yet, through the magic of math/CS, there are concrete **hashing algorithms** which ensure (in a mathematically-provable way!) "almost certain" $\overline{O}(1)$ lookup time

## Mathematical Strategy of Oracles {.crunch-title .title-12 .crunch-math .math-75 .crunch-ul}

* We'll use a **concrete**, **simplified hash function** to illustrate
* Mathematically we'll be able to get something like

$$
T(n) = \overline{O}(1 + \underbrace{\epsilon}_{\mathclap{\text{Collision rate}}} \cdot n)
$$

* Which tells us: **if** we had an oracle who could ensure near-0 collision rates, **then** $T(n) = \overline{O}(1)$.
* And, by a beautiful division-of-labor, **other** computer scientists [figure out](https://www.youtube.com/watch?v=OXuDhejxz_c) the near-0 collision rates part, giving us

$$
p^{‚úÖ} = [T(n) = \overline{O}(1 + \epsilon n)], q^{‚úÖ} = [\epsilon \approx 0],\text{ so } p \wedge q \implies T(n) \overset{‚úÖ}{=} \overline{O}(1).
$$

## Back to the Price List {.crunch-title .crunch-math .crunch-ul}

* Our hash function: **`hash(item)`** = **first letter of `item`**

$$
h(\texttt{x}) = \texttt{x[0]}
$$

* `h('Banana') = 'B'`, `h('Monkey') = 'M'`
* With this function in hand, we can create a length-26 **array**, one slot for each letter in alphabet, and then **write down (item, price) pairs** in **whatever slot `item` hashes to**

## The Importance of Differentiating Operations: *Insertion* vs. *Lookup* {.crunch-title .title-09}

* So far, we have $\overline{O}(1)$ **insertion** via hashing
* We also get $\overline{O}(1)$ **lookup!**
* When customer hands us an item (say, `'Banana'`), we compute the hash (`B`), look in that slot, and obtain the price for bananas.
* We also get $\overline{O}(1)$ **updating** (hash to find the old price, update it to have new price) and $\overline{O}(1)$ **deletion** (hash to find the slot containing the item, then erase it from that slot)

## So What's the Catch???

* **BLUEBERRIES** show up to ruin our day (as usual üòû)
* We hash, so far so good: `h('Blueberries') = 'B'`
* But then we go to the `B` slot and see that `(Bananas, 10)` is already there!!! Wtf do we do here... don't panic!
* The answer? We open our HW2 from DSAN 5500 and remember that we have our lovely friend the `LinkedList` that we can use whenever and however we want!

## Arrays vs. Linked Lists

* Jeff is hiding something here... Why jump to `LinkedList`? Why not just... another length-26 array, for example?
* For this we open up our Week 1 slides and remember the **stack** vs. **heap** distinction: we **know** how many letters in the alphabet, we **don't know** how many items starting with `B` (or, if we do, we want to be able to expand/contract our price list to handle new/discontinued items)
* Terminology for this kind of "hybrid" data structure: `HashTable` is an `Array` that **"degenerates into"** a `LinkedList` (when there are **collisions**)

## Look How Far We Came! {.crunch-title .crunch-ul .inline-90 .code-90}

* Last week: Only structure we knew allowing insertion (`LinkedList`) was $\overline{O}(n)$ for everythihg
* This week: New structure where suddenly everything is $\overline{O}(1)$, except in "unlucky" cases, in which it partially **"degenerates"** into a `LinkedList`
* $\implies$ The "inevitable" $\overline{O}(n)$ runtime has transformed into the unlucky worst-case **upper bound** [([feels like yesterday, all this was a dream](https://www.youtube.com/watch?v=CmghyKonz8E))]{style="font-size: 45% !important;"}
* $\implies$ By taking **core** data structures/algorithms from your toolkit, you can "piece together" **hybrid structures** whose *whole (runtime) is better than the sum of its parts*

## Hash Tables: tl;dr Edition {.crunch-title .crunch-ul .inline-90}

* **Keys** $k \in \mathcal{K}$ are plugged into a (deterministic) **hash function** $h: \mathcal{K} \rightarrow \{1, \ldots, N\}$, producing an **index** where $k$ is stored
* If **nothing at that index yet**, store $(k,v)$ in empty slot
* If **already an item at that index**, we have a ‚ö†Ô∏è**collision**‚ö†Ô∏è
* We could just **throw away** the old value (HW2 Part 1)
* Otherwise, need a way to store multiple items in one slot... (a way to **dynamically grow** storage at given index)
* Solution you know so far: **Linked Lists**
* New solution: **Binary Search Trees!**

# Binary Search Trees {data-stack-name="BSTs"}

* If you've been annoyed by how long we've talked about Linked Lists for... this is where it finally pays off!

## BST: The Final Missing Data Structure {.crunch-title .crunch-ul .code-90 .inline-90}

* Just a glorified `LinkedList`! We'll be able to take our `HashMap` and "drop in" the `BST` to play the role `LinkedList` is playing right now
* If collision, we'll create a `BST` with its $\overline{O}(\log(n))$ operations, rather than a `LinkedList` with its $\overline{O}(n)$ operations
* $\implies$ `HashMap` will go from:
  * $\overline{O}(1)$ best-case but $\overline{O}(n)$ worst-case to
  * $\overline{O}(1)$ best-case but $\overline{O}(\log_2(n))$ worst-case!

## Linked Lists + Divide-and-Conquer = BSTs {.crunch-title .title-11}

* By now, the word "Linked List" should make you groan, cross your arms and start tapping your feet with impatience
* "Here we go again... the Linked List is gonna make us **traverse through every single element** before we reach the one we're looking for" üòñ
* Linked List = Canon in D
* Binary Search Tree = Canon in D played by Hiromi Uehara...

## Visualizing BSTs {.smaller .crunch-title .crunch-col-output .crunch-details .cols-va}

```{python}
#| output-location: column
#| fig-align: center
from hw2 import LinkedList, InventoryItem, BinarySearchTree
bst = BinarySearchTree()
item1 = InventoryItem('Mango', 50)
bst.add(item1)
item2 = InventoryItem('Pickle', 60)
bst.add(item2)
item3 = InventoryItem('Artichoke', 55)
bst.add(item3)
item5 = InventoryItem('Banana', 123)
bst.add(item5)
item6 = InventoryItem('Aardvark', 11)
bst.add(item6)
HTML(visualize(bst))
```

## Practical Considerations {.text-90}

* **Hash Maps**: Only useful if keys are **hashable**
  * Python has a built-in `collections.abc.Hashable` class, such that `hash(my_obj)` works iff `isinstance(my_obj, Hashable)`
* **Binary Search Trees**: Only useful if keys have an **ordering**
  * "Standard" classes (`int`, `str`, `datetime`) come with implementations of ordering, but if you make **your own class** you need to **implement the ordering** for it!
* (**Linked Lists** still work for non-hashable/orderable objects!)

## Why `==`, `<`, `>=` "Just Work" {.crunch-title .smaller .crunch-ul}

* Not magic! Someone has **explicitly written a set of functions** telling Python **what to do** when it sees e.g. `obj1 < obj2`
* Example: let's implement an ordering of vectors $\mathbf{x} \in \mathbb{R}^2$ based on **Pareto dominance**

![](images/pareto.svg){fig-align="center"}

## Ordering Vectors via Pareto Dominance {.smaller .crunch-title .title-12}

```{python}
#| output-location: column
class UtilVector:
    def __init__(self, u1, u2):
        self.u1 = u1
        self.u2 = u2
    
    def __eq__(self, other):
        if not isinstance(other, UtilVector):
            return NotImplemented
        return self.u1 == other.u1 and self.u2 == other.u2

    def __ne__(self, other):
        if not isinstance(other, UtilVector):
            return NotImplemented
        return self.u1 != other.u1 or self.u2 != other.u2
    
    def __gt__(self, other):
        if not isinstance(other, UtilVector):
            return NotImplemented
        return self.u1 > other.u1 and self.u2 >= other.u2 or self.u1 >= other.u1 and self.u2 > other.u2

    def __ge__(self, other):
        return self.__gt__(other) or self.__eq__(other)
        
    def __lt__(self, other):
        if not isinstance(other, UtilVector):
            return NotImplemented
        return other.__gt__(self)

    def __le__(self, other):
        return self.__lt__(other) or self.__eq__(other)
xA = UtilVector(2, 2)
xB = UtilVector(3, 2)
print(xB > xA)
xC = UtilVector(2, 3)
print(xC > xB)
import itertools
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
x0 = UtilVector(4, 6)
util_vals = np.arange(0, 11, 0.5)
util_pairs = list(itertools.product(util_vals, util_vals))
util_df = pd.DataFrame(util_pairs, columns=['x','y'])
def compare_to_x0(row):
    row_vec = UtilVector(row['x'], row['y'])
    gt_result = int(row_vec > x0)
    lt_result = int(row_vec < x0)
    return gt_result - lt_result
util_df['greater'] = util_df.apply(compare_to_x0, axis=1)
#my_palette = sns.color_palette(['#E69F00','lightgray','#CCFFCC'])
my_palette = sns.color_palette(['#FF3535','lightgray','#35FF35'])
sns.relplot(
    data=util_df,
    x='x', y='y',
    hue='greater',
    palette=my_palette,
    marker='X', s=150
);
x0_df = pd.DataFrame({'x': [4], 'y': [6]})
plt.scatter(data=x0_df, x='x', y='y', color='black')
plt.gca().set_aspect('equal')
```

## Back to BSTs

* For HW2, we provide you with an `InventoryItem` class
* Two instance variables: `item_name` and `price`
* Equivalence relations:
  * `__eq__(other)`, `__ne__(other)`
* **Ordering relations**:
  * `__lt__(other)`, `__le__(other)`, `__gt__(other)`, `__ge__(other)`
* Bonus: `__repr__()` and `__str__()`

# Node Traversal: Computational Tree-Climbing {data-stack-name="Tree Traversal"}

## LLs $\rightarrow$ BSTs: The Hard Part

* When we were working with LinkedLists, we could access all items by just "looping through", from one element to the next, printing as we go along.
* But... for a BinarySearchTree, since our structure can now **branch** as we traverse it... How do we "loop through" a BST?
* **Two fundamentally different ways** to traverse every node in our BST
* "Opposites" of each other, so that one is often extremely efficient and the other extremely inefficient for a given task
* Your job as a data scientist is to **think carefully** about which one is **more efficient** for a given goal!

## Two Ways to Traverse: IRL Version {.smaller .crunch-title .title-12 .crunch-ul .crunch-callout}

* Imagine we're trying to learn about a topic $\tau$ using **Wikipedia**, so we find its article $\tau_0$
* There are two "extremes" in terms of strategies we could follow for learning, given the **contents** of the article as well as the **links** it contains to **other articles** 

::: {.callout-note icon="false" title="<i class='bi bi-info-circle pe-1'></i> Depth-First Search (DFS)" style="margin-bottom: 8px !important;"}

* Open $\tau_0$ and start reading it; When we encounter a **link** we **always click it** and **immediately start reading** the new article.
* If we hit an article with no links (or a dead end/broken link), we finish reading it and click the **back button**, picking up where we left off in the previous article. When we reach the end of $\tau_0$, we're done!

:::

::: {.callout-note icon="false" title="<i class='bi bi-info-circle pe-1'></i> Breadth-First Search (BFS)"}

* Bookmark $\tau_0$ in a folder called **"Level 0 Articles"**; open and start reading it
* When we encounter a **link**, we **put it in a "Level 1 Articles" folder**, but **continue reading $\tau_0$** until we reach the end.
* We then **open all "Level 1 Articles"** in new tabs, placing links we encounter in **these** articles into a **"Level 2 Articles"** folder, that we only start reading once all "Level 1 Articles" are read
* We continue like this, reading "Level 3 Articles" once we're done with "Level 2 Articles", "Level 4 Articles" once we're done with "Level 3 Articles", and so on. (Can you see a sense in which this is the **"opposite"** of DFS?)

:::

* ...Let's try them out! I clicked "Random Article" and got <a href='https://en.wikipedia.org/wiki/Eustache_de_Saint_Pierre' target='_blank'>Eustache de Saint Pierre <i class='bi bi-box-arrow-up-right ps-1'></i></a>

## Two Ways to Traverse: Picture Version {.smaller .crunch-title .crunch-details}

::: {.columns}
::: {.column width="50%"}

```{python}
#| fig-align: center
from hw2 import IterAlgorithm, NodeProcessor
visualize(bst)
```

:::
::: {.column width="50%"}

```{python}
print("DFS:")
dfs_processor = NodeProcessor(IterAlgorithm.DEPTH_FIRST)
#print(type(dfs_processor.node_container))
dfs_processor.iterate_over(bst)

print("\nBFS:")
bfs_processor = NodeProcessor(IterAlgorithm.BREADTH_FIRST)
#print(type(bfs_processor.node_container))
bfs_processor.iterate_over(bst)
```

:::
:::

## Two Ways to Traverse: In-Words Version {.smaller .crunch-title .title-12}

1. **Depth-First Search (DFS)**: With this approach, we iterate through the BST by **always taking the left child as the "next" child** until we hit a **leaf node** (which means, we cannot follow this left-child pointer any longer, since a leaf node does not have a left child or a right child!), and only at that point do we **back up** and take the **right children** we skipped.
2. **Breadth-First Search (BFS)**: This is the **"opposite"** of DFS in the sense that we traverse the tree level-by-level, **never moving to the next level of the tree** until we're **sure that we have visited every node on the current level**.

## Two Ways to Traverse: Animated Version {.smaller .crunch-title .title-12}

::: {layout="[1,1]"}

![**Depth-First Search** (from <a href='https://upload.wikimedia.org/wikipedia/commons/7/7f/Depth-First-Search.gif' target='_blank'>Wikimedia Commons</a>)](images/Depth-First-Search.gif){fig-align="center"}

![**Breadth-First Search** (from <a href='https://commons.wikimedia.org/wiki/File:Breadth-First-Search-Algorithm.gif' target='_blank'>Wikimedia Commons</a>)](images/Breadth-First-Search.gif){fig-align="center"}

:::

## Two Ways to Traverse: Underlying Data Structures Version {.smaller .crunch-title}

* Now that you have some intuition, you may be thinking that they might require very different code to implement ü§î
* This is where the **mathematical-formal linkage** between the two becomes ultra helpful!
* It turns out (and a full-on algorithmic theory course makes you prove) that

1. **Depth-First Search** can be accomplished by **processing nodes in an order determined by adding each to a *stack***, while
2. **Breadth-First Search** can be accomplished by **processing nodes in an order determined by adding each to a *queue***!

* $\implies$ Literally **identical code**, "pulling out" the word **stack** and replacing it with the word **queue** within your code (or vice-versa).
* If you have your Software Engineer Hats on, you'll recognize this as a job for an **abstraction layer!**

## Two Ways to Traverse: HW2 Version

* You'll make a class called `NodeProcessor`, with a **single** `iterate_over(tree)` function
* This function---**without any changes in the code or even any if statements!**---will be capable of both DFS and BFS
* It will take in a `ThingContainer` (could be a **stack** or a **queue**, you won't know which), which has two functions:
  * `put_new_thing_in(new_thing)`
  * `take_existing_thing_out()`

## Three Animals in the DFS Species

| DFS Procedure | Algorithm |
| - | - |
| Pre-Order Traversal | 1. **Print node**<br>2. Traverse left subtree<br>3. Traverse right subtree |
| **In-Order** Traversal üßê‚ÄºÔ∏è | 1. Traverse left subtree<br>2. **Print node**<br>3. Traverse right subtree |
| Post-Order Traversal | 1. Traverse left subtree<br>2. Traverse right subtree<br>3. **Print node** |

## The Three Animals Traverse our Inventory Tree {.smaller .crunch-title .title-10}

```{python}
#| fig-align: center
visualize(bst)
```

## Final Notes for HW2

* The last part challenges you to ask: **why stop at a hash based on just the *first* letter of the key?**
* We could just as easily use the first **two** letters:
* `h('AA') = 0`, `h('AB') = 1`, ..., `h('AZ') = 25`,
* `h('BA') = 26`, `h('BB') = 27`, ..., `h('BZ') = 51`,
* `h('CA') = 52`, ..., `h('ZZ') = 675`.
* You will see how this gets us **even closer to the elusive $O(1)$!** And we could get even closer with three letters, four letters, ... ü§îü§îü§î

